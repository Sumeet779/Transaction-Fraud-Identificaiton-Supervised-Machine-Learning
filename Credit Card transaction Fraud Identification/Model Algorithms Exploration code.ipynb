{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD DURATION:  0:00:00.001334\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Libraries to load\n",
    "# !pip install lightgbm\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print('LOAD DURATION: ', datetime.now() - start_time) # load time about 30 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96397, 22)\n",
      "CPU times: user 140 ms, sys: 27.7 ms, total: 168 ms\n",
      "Wall time: 177 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_zip_total_3</th>\n",
       "      <th>card_state_max_30</th>\n",
       "      <th>card_zip_total_14</th>\n",
       "      <th>card_merch_total_0</th>\n",
       "      <th>card_state_total_0</th>\n",
       "      <th>card_zip_total_0</th>\n",
       "      <th>merch_zip_avg_0</th>\n",
       "      <th>merch_dow_avg_3</th>\n",
       "      <th>Merchnum_avg_0</th>\n",
       "      <th>merch_dow_avg_1</th>\n",
       "      <th>...</th>\n",
       "      <th>merch_state_avg_0</th>\n",
       "      <th>Merchnum_avg_1</th>\n",
       "      <th>card_merch_avg_30</th>\n",
       "      <th>card_merch_max_30</th>\n",
       "      <th>card_zip_avg_1</th>\n",
       "      <th>card_merch_avg_3</th>\n",
       "      <th>merch_state_avg_1</th>\n",
       "      <th>card_zip_avg_0</th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>...</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>...</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>...</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>...</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>...</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   card_zip_total_3  card_state_max_30  card_zip_total_14  card_merch_total_0  \\\n",
       "0              3.62               3.62               3.62                3.62   \n",
       "1             31.42              31.42              31.42               31.42   \n",
       "2            178.49             178.49             178.49              178.49   \n",
       "3              3.62               3.62               3.62                3.62   \n",
       "4              7.24               3.62               7.24                7.24   \n",
       "\n",
       "   card_state_total_0  card_zip_total_0  merch_zip_avg_0  merch_dow_avg_3  \\\n",
       "0                3.62              3.62             3.62             3.62   \n",
       "1               31.42             31.42            31.42            31.42   \n",
       "2              178.49            178.49           178.49           178.49   \n",
       "3                3.62              3.62             3.62             3.62   \n",
       "4                7.24              7.24             3.62             3.62   \n",
       "\n",
       "   Merchnum_avg_0  merch_dow_avg_1  ...  merch_state_avg_0  Merchnum_avg_1  \\\n",
       "0            3.62             3.62  ...               3.62            3.62   \n",
       "1           31.42            31.42  ...              31.42           31.42   \n",
       "2          178.49           178.49  ...             178.49          178.49   \n",
       "3            3.62             3.62  ...               3.62            3.62   \n",
       "4            3.62             3.62  ...               3.62            3.62   \n",
       "\n",
       "   card_merch_avg_30  card_merch_max_30  card_zip_avg_1  card_merch_avg_3  \\\n",
       "0               3.62               3.62            3.62              3.62   \n",
       "1              31.42              31.42           31.42             31.42   \n",
       "2             178.49             178.49          178.49            178.49   \n",
       "3               3.62               3.62            3.62              3.62   \n",
       "4               3.62               3.62            3.62              3.62   \n",
       "\n",
       "   merch_state_avg_1  card_zip_avg_0  Recnum  Fraud  \n",
       "0               3.62            3.62       1      0  \n",
       "1              31.42           31.42       2      0  \n",
       "2             178.49          178.49       3      0  \n",
       "3               3.62            3.62       4      0  \n",
       "4               3.62            3.62       5      0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "vars = pd.read_csv('vars_final.csv')\n",
    "print(vars.shape)\n",
    "vars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>card_zip_total_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>card_state_max_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>card_zip_total_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>card_merch_total_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>card_state_total_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>card_zip_total_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>merch_zip_avg_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>merch_dow_avg_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Merchnum_avg_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>merch_dow_avg_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>merch_dow_avg_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>merch_zip_avg_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>merch_state_avg_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Merchnum_avg_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>card_merch_avg_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>card_merch_max_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>card_zip_avg_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>card_merch_avg_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>merch_state_avg_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>card_zip_avg_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         variable name\n",
       "0     card_zip_total_3\n",
       "1    card_state_max_30\n",
       "2    card_zip_total_14\n",
       "3   card_merch_total_0\n",
       "4   card_state_total_0\n",
       "5     card_zip_total_0\n",
       "6      merch_zip_avg_0\n",
       "7      merch_dow_avg_3\n",
       "8       Merchnum_avg_0\n",
       "9      merch_dow_avg_1\n",
       "10     merch_dow_avg_0\n",
       "11     merch_zip_avg_1\n",
       "12   merch_state_avg_0\n",
       "13      Merchnum_avg_1\n",
       "14   card_merch_avg_30\n",
       "15   card_merch_max_30\n",
       "16      card_zip_avg_1\n",
       "17    card_merch_avg_3\n",
       "18   merch_state_avg_1\n",
       "19      card_zip_avg_0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_vars = pd.read_csv('final_vars_list.csv')\n",
    "final_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Recnum',\n",
       " 'Fraud',\n",
       " 'card_zip_total_3',\n",
       " 'card_state_max_30',\n",
       " 'card_zip_total_14',\n",
       " 'card_merch_total_0',\n",
       " 'card_state_total_0',\n",
       " 'card_zip_total_0',\n",
       " 'merch_zip_avg_0',\n",
       " 'merch_dow_avg_3',\n",
       " 'Merchnum_avg_0',\n",
       " 'merch_dow_avg_1',\n",
       " 'merch_dow_avg_0',\n",
       " 'merch_zip_avg_1',\n",
       " 'merch_state_avg_0',\n",
       " 'Merchnum_avg_1',\n",
       " 'card_merch_avg_30']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numvars = 15   # 5, 10, 15, 20\n",
    "final_vars_list = ['Recnum','Fraud']\n",
    "for i in range(numvars):\n",
    "    final_vars_list.append(final_vars.iloc[i]['variable name'])\n",
    "    \n",
    "final_vars_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>card_zip_total_3</th>\n",
       "      <th>card_state_max_30</th>\n",
       "      <th>card_zip_total_14</th>\n",
       "      <th>card_merch_total_0</th>\n",
       "      <th>card_state_total_0</th>\n",
       "      <th>card_zip_total_0</th>\n",
       "      <th>merch_zip_avg_0</th>\n",
       "      <th>merch_dow_avg_3</th>\n",
       "      <th>Merchnum_avg_0</th>\n",
       "      <th>merch_dow_avg_1</th>\n",
       "      <th>merch_dow_avg_0</th>\n",
       "      <th>merch_zip_avg_1</th>\n",
       "      <th>merch_state_avg_0</th>\n",
       "      <th>Merchnum_avg_1</th>\n",
       "      <th>card_merch_avg_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recnum  Fraud  card_zip_total_3  card_state_max_30  card_zip_total_14  \\\n",
       "0       1      0              3.62               3.62               3.62   \n",
       "1       2      0             31.42              31.42              31.42   \n",
       "2       3      0            178.49             178.49             178.49   \n",
       "3       4      0              3.62               3.62               3.62   \n",
       "4       5      0              7.24               3.62               7.24   \n",
       "\n",
       "   card_merch_total_0  card_state_total_0  card_zip_total_0  merch_zip_avg_0  \\\n",
       "0                3.62                3.62              3.62             3.62   \n",
       "1               31.42               31.42             31.42            31.42   \n",
       "2              178.49              178.49            178.49           178.49   \n",
       "3                3.62                3.62              3.62             3.62   \n",
       "4                7.24                7.24              7.24             3.62   \n",
       "\n",
       "   merch_dow_avg_3  Merchnum_avg_0  merch_dow_avg_1  merch_dow_avg_0  \\\n",
       "0             3.62            3.62             3.62             3.62   \n",
       "1            31.42           31.42            31.42            31.42   \n",
       "2           178.49          178.49           178.49           178.49   \n",
       "3             3.62            3.62             3.62             3.62   \n",
       "4             3.62            3.62             3.62             3.62   \n",
       "\n",
       "   merch_zip_avg_1  merch_state_avg_0  Merchnum_avg_1  card_merch_avg_30  \n",
       "0             3.62               3.62            3.62               3.62  \n",
       "1            31.42              31.42           31.42              31.42  \n",
       "2           178.49             178.49          178.49             178.49  \n",
       "3             3.62               3.62            3.62               3.62  \n",
       "4             3.62               3.62            3.62               3.62  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars = vars.filter(final_vars_list,axis=1)\n",
    "vars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to cap variables. For some problems it helps\n",
    "Clip = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vars.rename(columns={'fraud_label':'Fraud'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1059"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars['Fraud'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>card_zip_total_3</th>\n",
       "      <th>card_state_max_30</th>\n",
       "      <th>card_zip_total_14</th>\n",
       "      <th>card_merch_total_0</th>\n",
       "      <th>card_state_total_0</th>\n",
       "      <th>card_zip_total_0</th>\n",
       "      <th>merch_zip_avg_0</th>\n",
       "      <th>merch_dow_avg_3</th>\n",
       "      <th>Merchnum_avg_0</th>\n",
       "      <th>merch_dow_avg_1</th>\n",
       "      <th>merch_dow_avg_0</th>\n",
       "      <th>merch_zip_avg_1</th>\n",
       "      <th>merch_state_avg_0</th>\n",
       "      <th>Merchnum_avg_1</th>\n",
       "      <th>card_merch_avg_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.420000</td>\n",
       "      <td>31.420000</td>\n",
       "      <td>31.420000</td>\n",
       "      <td>31.420000</td>\n",
       "      <td>31.420000</td>\n",
       "      <td>31.420000</td>\n",
       "      <td>31.420000</td>\n",
       "      <td>31.420000</td>\n",
       "      <td>31.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.490000</td>\n",
       "      <td>178.490000</td>\n",
       "      <td>178.490000</td>\n",
       "      <td>178.490000</td>\n",
       "      <td>178.490000</td>\n",
       "      <td>178.490000</td>\n",
       "      <td>178.490000</td>\n",
       "      <td>178.490000</td>\n",
       "      <td>178.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.632500</td>\n",
       "      <td>3.632500</td>\n",
       "      <td>3.632500</td>\n",
       "      <td>3.632500</td>\n",
       "      <td>3.632500</td>\n",
       "      <td>3.632500</td>\n",
       "      <td>3.632500</td>\n",
       "      <td>3.632500</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.630000</td>\n",
       "      <td>3.630000</td>\n",
       "      <td>3.630000</td>\n",
       "      <td>3.630000</td>\n",
       "      <td>3.630000</td>\n",
       "      <td>3.630000</td>\n",
       "      <td>3.630000</td>\n",
       "      <td>3.630000</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.320000</td>\n",
       "      <td>230.320000</td>\n",
       "      <td>230.320000</td>\n",
       "      <td>230.320000</td>\n",
       "      <td>230.320000</td>\n",
       "      <td>230.320000</td>\n",
       "      <td>230.320000</td>\n",
       "      <td>230.320000</td>\n",
       "      <td>230.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.110000</td>\n",
       "      <td>62.110000</td>\n",
       "      <td>62.110000</td>\n",
       "      <td>62.110000</td>\n",
       "      <td>62.110000</td>\n",
       "      <td>62.110000</td>\n",
       "      <td>62.110000</td>\n",
       "      <td>62.110000</td>\n",
       "      <td>62.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10.86</td>\n",
       "      <td>3.62</td>\n",
       "      <td>10.86</td>\n",
       "      <td>10.86</td>\n",
       "      <td>10.86</td>\n",
       "      <td>10.86</td>\n",
       "      <td>3.628333</td>\n",
       "      <td>3.628333</td>\n",
       "      <td>3.628333</td>\n",
       "      <td>3.628333</td>\n",
       "      <td>3.628333</td>\n",
       "      <td>3.628333</td>\n",
       "      <td>3.628333</td>\n",
       "      <td>3.628333</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recnum  Fraud  card_zip_total_3  card_state_max_30  card_zip_total_14  \\\n",
       "0       1      0              3.62               3.62               3.62   \n",
       "1       2      0             31.42              31.42              31.42   \n",
       "2       3      0            178.49             178.49             178.49   \n",
       "3       4      0              3.62               3.62               3.62   \n",
       "4       5      0              7.24               3.62               7.24   \n",
       "5       6      0              3.67               3.67               3.67   \n",
       "6       7      0              3.62               3.62               3.62   \n",
       "7       8      0            230.32             230.32             230.32   \n",
       "8       9      0             62.11              62.11              62.11   \n",
       "9      10      0             10.86               3.62              10.86   \n",
       "\n",
       "   card_merch_total_0  card_state_total_0  card_zip_total_0  merch_zip_avg_0  \\\n",
       "0                3.62                3.62              3.62         3.620000   \n",
       "1               31.42               31.42             31.42        31.420000   \n",
       "2              178.49              178.49            178.49       178.490000   \n",
       "3                3.62                3.62              3.62         3.620000   \n",
       "4                7.24                7.24              7.24         3.620000   \n",
       "5                3.67                3.67              3.67         3.632500   \n",
       "6                3.62                3.62              3.62         3.630000   \n",
       "7              230.32              230.32            230.32       230.320000   \n",
       "8               62.11               62.11             62.11        62.110000   \n",
       "9               10.86               10.86             10.86         3.628333   \n",
       "\n",
       "   merch_dow_avg_3  Merchnum_avg_0  merch_dow_avg_1  merch_dow_avg_0  \\\n",
       "0         3.620000        3.620000         3.620000         3.620000   \n",
       "1        31.420000       31.420000        31.420000        31.420000   \n",
       "2       178.490000      178.490000       178.490000       178.490000   \n",
       "3         3.620000        3.620000         3.620000         3.620000   \n",
       "4         3.620000        3.620000         3.620000         3.620000   \n",
       "5         3.632500        3.632500         3.632500         3.632500   \n",
       "6         3.630000        3.630000         3.630000         3.630000   \n",
       "7       230.320000      230.320000       230.320000       230.320000   \n",
       "8        62.110000       62.110000        62.110000        62.110000   \n",
       "9         3.628333        3.628333         3.628333         3.628333   \n",
       "\n",
       "   merch_zip_avg_1  merch_state_avg_0  Merchnum_avg_1  card_merch_avg_30  \n",
       "0         3.620000           3.620000        3.620000               3.62  \n",
       "1        31.420000          31.420000       31.420000              31.42  \n",
       "2       178.490000         178.490000      178.490000             178.49  \n",
       "3         3.620000           3.620000        3.620000               3.62  \n",
       "4         3.620000           3.620000        3.620000               3.62  \n",
       "5         3.632500           3.632500        3.632500               3.67  \n",
       "6         3.630000           3.630000        3.630000               3.62  \n",
       "7       230.320000         230.320000      230.320000             230.32  \n",
       "8        62.110000          62.110000       62.110000              62.11  \n",
       "9         3.628333           3.628333        3.628333               3.62  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96397, 17)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>card_zip_total_3</th>\n",
       "      <th>card_state_max_30</th>\n",
       "      <th>card_zip_total_14</th>\n",
       "      <th>card_merch_total_0</th>\n",
       "      <th>card_state_total_0</th>\n",
       "      <th>card_zip_total_0</th>\n",
       "      <th>merch_zip_avg_0</th>\n",
       "      <th>merch_dow_avg_3</th>\n",
       "      <th>Merchnum_avg_0</th>\n",
       "      <th>merch_dow_avg_1</th>\n",
       "      <th>merch_dow_avg_0</th>\n",
       "      <th>merch_zip_avg_1</th>\n",
       "      <th>merch_state_avg_0</th>\n",
       "      <th>Merchnum_avg_1</th>\n",
       "      <th>card_merch_avg_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>48365.481820</td>\n",
       "      <td>0.010986</td>\n",
       "      <td>642.134217</td>\n",
       "      <td>708.830517</td>\n",
       "      <td>806.656625</td>\n",
       "      <td>529.059538</td>\n",
       "      <td>553.959547</td>\n",
       "      <td>531.796481</td>\n",
       "      <td>395.318386</td>\n",
       "      <td>395.555635</td>\n",
       "      <td>395.555635</td>\n",
       "      <td>395.555635</td>\n",
       "      <td>395.555635</td>\n",
       "      <td>397.298177</td>\n",
       "      <td>395.413364</td>\n",
       "      <td>397.964184</td>\n",
       "      <td>404.220029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27945.003883</td>\n",
       "      <td>0.104236</td>\n",
       "      <td>4066.803407</td>\n",
       "      <td>1298.414384</td>\n",
       "      <td>4186.923501</td>\n",
       "      <td>2622.052105</td>\n",
       "      <td>2640.513453</td>\n",
       "      <td>2623.087903</td>\n",
       "      <td>759.254251</td>\n",
       "      <td>743.275734</td>\n",
       "      <td>743.275734</td>\n",
       "      <td>743.275734</td>\n",
       "      <td>743.275734</td>\n",
       "      <td>748.349808</td>\n",
       "      <td>759.395837</td>\n",
       "      <td>731.741737</td>\n",
       "      <td>787.939820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24154.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.350000</td>\n",
       "      <td>87.030000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>46.620000</td>\n",
       "      <td>49.120000</td>\n",
       "      <td>47.330000</td>\n",
       "      <td>39.950000</td>\n",
       "      <td>40.010000</td>\n",
       "      <td>40.010000</td>\n",
       "      <td>40.010000</td>\n",
       "      <td>40.010000</td>\n",
       "      <td>44.750000</td>\n",
       "      <td>39.950000</td>\n",
       "      <td>45.348000</td>\n",
       "      <td>42.473333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>48365.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.770000</td>\n",
       "      <td>325.540000</td>\n",
       "      <td>257.000000</td>\n",
       "      <td>159.400000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>160.940000</td>\n",
       "      <td>159.055000</td>\n",
       "      <td>163.640000</td>\n",
       "      <td>163.640000</td>\n",
       "      <td>163.640000</td>\n",
       "      <td>163.640000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>180.910000</td>\n",
       "      <td>165.485000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>72578.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>556.940000</td>\n",
       "      <td>919.010000</td>\n",
       "      <td>718.640000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>514.680000</td>\n",
       "      <td>495.900000</td>\n",
       "      <td>452.310000</td>\n",
       "      <td>455.800000</td>\n",
       "      <td>455.800000</td>\n",
       "      <td>455.800000</td>\n",
       "      <td>455.800000</td>\n",
       "      <td>464.830000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>463.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96753.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>217467.180000</td>\n",
       "      <td>217467.180000</td>\n",
       "      <td>217467.180000</td>\n",
       "      <td>28392.840000</td>\n",
       "      <td>26910.000000</td>\n",
       "      <td>26910.000000</td>\n",
       "      <td>26910.000000</td>\n",
       "      <td>26910.000000</td>\n",
       "      <td>28392.840000</td>\n",
       "      <td>28392.840000</td>\n",
       "      <td>26910.000000</td>\n",
       "      <td>28392.840000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Recnum         Fraud  card_zip_total_3  card_state_max_30  \\\n",
       "count  96397.000000  96397.000000      96397.000000       96397.000000   \n",
       "mean   48365.481820      0.010986        642.134217         708.830517   \n",
       "std    27945.003883      0.104236       4066.803407        1298.414384   \n",
       "min        1.000000      0.000000          0.010000           0.010000   \n",
       "25%    24154.000000      0.000000         58.350000          87.030000   \n",
       "50%    48365.000000      0.000000        185.770000         325.540000   \n",
       "75%    72578.000000      0.000000        556.940000         919.010000   \n",
       "max    96753.000000      1.000000     306633.410000       47900.000000   \n",
       "\n",
       "       card_zip_total_14  card_merch_total_0  card_state_total_0  \\\n",
       "count       96397.000000        96397.000000        96397.000000   \n",
       "mean          806.656625          529.059538          553.959547   \n",
       "std          4186.923501         2622.052105         2640.513453   \n",
       "min             0.010000            0.010000            0.010000   \n",
       "25%            85.000000           46.620000           49.120000   \n",
       "50%           257.000000          159.400000          169.000000   \n",
       "75%           718.640000          494.000000          514.680000   \n",
       "max        306633.410000       217467.180000       217467.180000   \n",
       "\n",
       "       card_zip_total_0  merch_zip_avg_0  merch_dow_avg_3  Merchnum_avg_0  \\\n",
       "count      96397.000000     96397.000000     96397.000000    96397.000000   \n",
       "mean         531.796481       395.318386       395.555635      395.555635   \n",
       "std         2623.087903       759.254251       743.275734      743.275734   \n",
       "min            0.010000         0.010000         0.010000        0.010000   \n",
       "25%           47.330000        39.950000        40.010000       40.010000   \n",
       "50%          160.940000       159.055000       163.640000      163.640000   \n",
       "75%          495.900000       452.310000       455.800000      455.800000   \n",
       "max       217467.180000     28392.840000     26910.000000    26910.000000   \n",
       "\n",
       "       merch_dow_avg_1  merch_dow_avg_0  merch_zip_avg_1  merch_state_avg_0  \\\n",
       "count     96397.000000     96397.000000     96397.000000       96397.000000   \n",
       "mean        395.555635       395.555635       397.298177         395.413364   \n",
       "std         743.275734       743.275734       748.349808         759.395837   \n",
       "min           0.010000         0.010000         0.010000           0.010000   \n",
       "25%          40.010000        40.010000        44.750000          39.950000   \n",
       "50%         163.640000       163.640000       175.000000         159.000000   \n",
       "75%         455.800000       455.800000       464.830000         452.000000   \n",
       "max       26910.000000     26910.000000     28392.840000       28392.840000   \n",
       "\n",
       "       Merchnum_avg_1  card_merch_avg_30  \n",
       "count    96397.000000       96397.000000  \n",
       "mean       397.964184         404.220029  \n",
       "std        731.741737         787.939820  \n",
       "min          0.010000           0.010000  \n",
       "25%         45.348000          42.473333  \n",
       "50%        180.910000         165.485000  \n",
       "75%        470.000000         463.380000  \n",
       "max      26910.000000       28392.840000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fraud\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_save = vars['Recnum']\n",
    "Y_save = pd.DataFrame(vars.loc[:,'Fraud'])\n",
    "Y_save.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale and truncate field values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_zip_total_3</th>\n",
       "      <th>card_state_max_30</th>\n",
       "      <th>card_zip_total_14</th>\n",
       "      <th>card_merch_total_0</th>\n",
       "      <th>card_state_total_0</th>\n",
       "      <th>card_zip_total_0</th>\n",
       "      <th>merch_zip_avg_0</th>\n",
       "      <th>merch_dow_avg_3</th>\n",
       "      <th>Merchnum_avg_0</th>\n",
       "      <th>merch_dow_avg_1</th>\n",
       "      <th>merch_dow_avg_0</th>\n",
       "      <th>merch_zip_avg_1</th>\n",
       "      <th>merch_state_avg_0</th>\n",
       "      <th>Merchnum_avg_1</th>\n",
       "      <th>card_merch_avg_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>642.134217</td>\n",
       "      <td>708.830517</td>\n",
       "      <td>806.656625</td>\n",
       "      <td>529.059538</td>\n",
       "      <td>553.959547</td>\n",
       "      <td>531.796481</td>\n",
       "      <td>395.318386</td>\n",
       "      <td>395.555635</td>\n",
       "      <td>395.555635</td>\n",
       "      <td>395.555635</td>\n",
       "      <td>395.555635</td>\n",
       "      <td>397.298177</td>\n",
       "      <td>395.413364</td>\n",
       "      <td>397.964184</td>\n",
       "      <td>404.220029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4066.803407</td>\n",
       "      <td>1298.414384</td>\n",
       "      <td>4186.923501</td>\n",
       "      <td>2622.052105</td>\n",
       "      <td>2640.513453</td>\n",
       "      <td>2623.087903</td>\n",
       "      <td>759.254251</td>\n",
       "      <td>743.275734</td>\n",
       "      <td>743.275734</td>\n",
       "      <td>743.275734</td>\n",
       "      <td>743.275734</td>\n",
       "      <td>748.349808</td>\n",
       "      <td>759.395837</td>\n",
       "      <td>731.741737</td>\n",
       "      <td>787.939820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>58.350000</td>\n",
       "      <td>87.030000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>46.620000</td>\n",
       "      <td>49.120000</td>\n",
       "      <td>47.330000</td>\n",
       "      <td>39.950000</td>\n",
       "      <td>40.010000</td>\n",
       "      <td>40.010000</td>\n",
       "      <td>40.010000</td>\n",
       "      <td>40.010000</td>\n",
       "      <td>44.750000</td>\n",
       "      <td>39.950000</td>\n",
       "      <td>45.348000</td>\n",
       "      <td>42.473333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>185.770000</td>\n",
       "      <td>325.540000</td>\n",
       "      <td>257.000000</td>\n",
       "      <td>159.400000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>160.940000</td>\n",
       "      <td>159.055000</td>\n",
       "      <td>163.640000</td>\n",
       "      <td>163.640000</td>\n",
       "      <td>163.640000</td>\n",
       "      <td>163.640000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>180.910000</td>\n",
       "      <td>165.485000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>556.940000</td>\n",
       "      <td>919.010000</td>\n",
       "      <td>718.640000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>514.680000</td>\n",
       "      <td>495.900000</td>\n",
       "      <td>452.310000</td>\n",
       "      <td>455.800000</td>\n",
       "      <td>455.800000</td>\n",
       "      <td>455.800000</td>\n",
       "      <td>455.800000</td>\n",
       "      <td>464.830000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>463.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>306633.410000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>217467.180000</td>\n",
       "      <td>217467.180000</td>\n",
       "      <td>217467.180000</td>\n",
       "      <td>28392.840000</td>\n",
       "      <td>26910.000000</td>\n",
       "      <td>26910.000000</td>\n",
       "      <td>26910.000000</td>\n",
       "      <td>26910.000000</td>\n",
       "      <td>28392.840000</td>\n",
       "      <td>28392.840000</td>\n",
       "      <td>26910.000000</td>\n",
       "      <td>28392.840000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       card_zip_total_3  card_state_max_30  card_zip_total_14  \\\n",
       "count      96397.000000       96397.000000       96397.000000   \n",
       "mean         642.134217         708.830517         806.656625   \n",
       "std         4066.803407        1298.414384        4186.923501   \n",
       "min            0.010000           0.010000           0.010000   \n",
       "25%           58.350000          87.030000          85.000000   \n",
       "50%          185.770000         325.540000         257.000000   \n",
       "75%          556.940000         919.010000         718.640000   \n",
       "max       306633.410000       47900.000000      306633.410000   \n",
       "\n",
       "       card_merch_total_0  card_state_total_0  card_zip_total_0  \\\n",
       "count        96397.000000        96397.000000      96397.000000   \n",
       "mean           529.059538          553.959547        531.796481   \n",
       "std           2622.052105         2640.513453       2623.087903   \n",
       "min              0.010000            0.010000          0.010000   \n",
       "25%             46.620000           49.120000         47.330000   \n",
       "50%            159.400000          169.000000        160.940000   \n",
       "75%            494.000000          514.680000        495.900000   \n",
       "max         217467.180000       217467.180000     217467.180000   \n",
       "\n",
       "       merch_zip_avg_0  merch_dow_avg_3  Merchnum_avg_0  merch_dow_avg_1  \\\n",
       "count     96397.000000     96397.000000    96397.000000     96397.000000   \n",
       "mean        395.318386       395.555635      395.555635       395.555635   \n",
       "std         759.254251       743.275734      743.275734       743.275734   \n",
       "min           0.010000         0.010000        0.010000         0.010000   \n",
       "25%          39.950000        40.010000       40.010000        40.010000   \n",
       "50%         159.055000       163.640000      163.640000       163.640000   \n",
       "75%         452.310000       455.800000      455.800000       455.800000   \n",
       "max       28392.840000     26910.000000    26910.000000     26910.000000   \n",
       "\n",
       "       merch_dow_avg_0  merch_zip_avg_1  merch_state_avg_0  Merchnum_avg_1  \\\n",
       "count     96397.000000     96397.000000       96397.000000    96397.000000   \n",
       "mean        395.555635       397.298177         395.413364      397.964184   \n",
       "std         743.275734       748.349808         759.395837      731.741737   \n",
       "min           0.010000         0.010000           0.010000        0.010000   \n",
       "25%          40.010000        44.750000          39.950000       45.348000   \n",
       "50%         163.640000       175.000000         159.000000      180.910000   \n",
       "75%         455.800000       464.830000         452.000000      470.000000   \n",
       "max       26910.000000     28392.840000       28392.840000    26910.000000   \n",
       "\n",
       "       card_merch_avg_30  \n",
       "count       96397.000000  \n",
       "mean          404.220029  \n",
       "std           787.939820  \n",
       "min             0.010000  \n",
       "25%            42.473333  \n",
       "50%           165.485000  \n",
       "75%           463.380000  \n",
       "max         28392.840000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_no_scaling = vars.drop(columns = ['Recnum','Fraud'])\n",
    "X_no_scaling.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = (X_no_scaling - X_no_scaling.mean()) / X_no_scaling.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_zip_total_3</th>\n",
       "      <th>card_state_max_30</th>\n",
       "      <th>card_zip_total_14</th>\n",
       "      <th>card_merch_total_0</th>\n",
       "      <th>card_state_total_0</th>\n",
       "      <th>card_zip_total_0</th>\n",
       "      <th>merch_zip_avg_0</th>\n",
       "      <th>merch_dow_avg_3</th>\n",
       "      <th>Merchnum_avg_0</th>\n",
       "      <th>merch_dow_avg_1</th>\n",
       "      <th>merch_dow_avg_0</th>\n",
       "      <th>merch_zip_avg_1</th>\n",
       "      <th>merch_state_avg_0</th>\n",
       "      <th>Merchnum_avg_1</th>\n",
       "      <th>card_merch_avg_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.012607</td>\n",
       "      <td>-0.010834</td>\n",
       "      <td>-0.012245</td>\n",
       "      <td>-0.011778</td>\n",
       "      <td>-0.011640</td>\n",
       "      <td>-0.011770</td>\n",
       "      <td>-0.007430</td>\n",
       "      <td>-0.007034</td>\n",
       "      <td>-0.007034</td>\n",
       "      <td>-0.007034</td>\n",
       "      <td>-0.007034</td>\n",
       "      <td>-0.007672</td>\n",
       "      <td>-0.007396</td>\n",
       "      <td>-0.007271</td>\n",
       "      <td>-0.008218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.448265</td>\n",
       "      <td>0.821922</td>\n",
       "      <td>0.496200</td>\n",
       "      <td>0.482831</td>\n",
       "      <td>0.495104</td>\n",
       "      <td>0.483555</td>\n",
       "      <td>0.859903</td>\n",
       "      <td>0.871973</td>\n",
       "      <td>0.871973</td>\n",
       "      <td>0.871973</td>\n",
       "      <td>0.871973</td>\n",
       "      <td>0.853230</td>\n",
       "      <td>0.860437</td>\n",
       "      <td>0.865505</td>\n",
       "      <td>0.846484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.157894</td>\n",
       "      <td>-0.545912</td>\n",
       "      <td>-0.192659</td>\n",
       "      <td>-0.201769</td>\n",
       "      <td>-0.209789</td>\n",
       "      <td>-0.202733</td>\n",
       "      <td>-0.520654</td>\n",
       "      <td>-0.532165</td>\n",
       "      <td>-0.532165</td>\n",
       "      <td>-0.532165</td>\n",
       "      <td>-0.532165</td>\n",
       "      <td>-0.530886</td>\n",
       "      <td>-0.520682</td>\n",
       "      <td>-0.543845</td>\n",
       "      <td>-0.512996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.143549</td>\n",
       "      <td>-0.478892</td>\n",
       "      <td>-0.172360</td>\n",
       "      <td>-0.183993</td>\n",
       "      <td>-0.191190</td>\n",
       "      <td>-0.184693</td>\n",
       "      <td>-0.468049</td>\n",
       "      <td>-0.478350</td>\n",
       "      <td>-0.478350</td>\n",
       "      <td>-0.478350</td>\n",
       "      <td>-0.478350</td>\n",
       "      <td>-0.471101</td>\n",
       "      <td>-0.468087</td>\n",
       "      <td>-0.481886</td>\n",
       "      <td>-0.459104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.112217</td>\n",
       "      <td>-0.295199</td>\n",
       "      <td>-0.131279</td>\n",
       "      <td>-0.140981</td>\n",
       "      <td>-0.145790</td>\n",
       "      <td>-0.141382</td>\n",
       "      <td>-0.311178</td>\n",
       "      <td>-0.312018</td>\n",
       "      <td>-0.312018</td>\n",
       "      <td>-0.312018</td>\n",
       "      <td>-0.312018</td>\n",
       "      <td>-0.297051</td>\n",
       "      <td>-0.311318</td>\n",
       "      <td>-0.296627</td>\n",
       "      <td>-0.302986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.020949</td>\n",
       "      <td>0.161874</td>\n",
       "      <td>-0.021022</td>\n",
       "      <td>-0.013371</td>\n",
       "      <td>-0.014876</td>\n",
       "      <td>-0.013685</td>\n",
       "      <td>0.075063</td>\n",
       "      <td>0.081053</td>\n",
       "      <td>0.081053</td>\n",
       "      <td>0.081053</td>\n",
       "      <td>0.081053</td>\n",
       "      <td>0.090241</td>\n",
       "      <td>0.074515</td>\n",
       "      <td>0.098444</td>\n",
       "      <td>0.075082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       card_zip_total_3  card_state_max_30  card_zip_total_14  \\\n",
       "count      96397.000000       96397.000000       96397.000000   \n",
       "mean          -0.012607          -0.010834          -0.012245   \n",
       "std            0.448265           0.821922           0.496200   \n",
       "min           -0.157894          -0.545912          -0.192659   \n",
       "25%           -0.143549          -0.478892          -0.172360   \n",
       "50%           -0.112217          -0.295199          -0.131279   \n",
       "75%           -0.020949           0.161874          -0.021022   \n",
       "max           10.000000          10.000000          10.000000   \n",
       "\n",
       "       card_merch_total_0  card_state_total_0  card_zip_total_0  \\\n",
       "count        96397.000000        96397.000000      96397.000000   \n",
       "mean            -0.011778           -0.011640         -0.011770   \n",
       "std              0.482831            0.495104          0.483555   \n",
       "min             -0.201769           -0.209789         -0.202733   \n",
       "25%             -0.183993           -0.191190         -0.184693   \n",
       "50%             -0.140981           -0.145790         -0.141382   \n",
       "75%             -0.013371           -0.014876         -0.013685   \n",
       "max             10.000000           10.000000         10.000000   \n",
       "\n",
       "       merch_zip_avg_0  merch_dow_avg_3  Merchnum_avg_0  merch_dow_avg_1  \\\n",
       "count     96397.000000     96397.000000    96397.000000     96397.000000   \n",
       "mean         -0.007430        -0.007034       -0.007034        -0.007034   \n",
       "std           0.859903         0.871973        0.871973         0.871973   \n",
       "min          -0.520654        -0.532165       -0.532165        -0.532165   \n",
       "25%          -0.468049        -0.478350       -0.478350        -0.478350   \n",
       "50%          -0.311178        -0.312018       -0.312018        -0.312018   \n",
       "75%           0.075063         0.081053        0.081053         0.081053   \n",
       "max          10.000000        10.000000       10.000000        10.000000   \n",
       "\n",
       "       merch_dow_avg_0  merch_zip_avg_1  merch_state_avg_0  Merchnum_avg_1  \\\n",
       "count     96397.000000     96397.000000       96397.000000    96397.000000   \n",
       "mean         -0.007034        -0.007672          -0.007396       -0.007271   \n",
       "std           0.871973         0.853230           0.860437        0.865505   \n",
       "min          -0.532165        -0.530886          -0.520682       -0.543845   \n",
       "25%          -0.478350        -0.471101          -0.468087       -0.481886   \n",
       "50%          -0.312018        -0.297051          -0.311318       -0.296627   \n",
       "75%           0.081053         0.090241           0.074515        0.098444   \n",
       "max          10.000000        10.000000          10.000000       10.000000   \n",
       "\n",
       "       card_merch_avg_30  \n",
       "count       96397.000000  \n",
       "mean           -0.008218  \n",
       "std             0.846484  \n",
       "min            -0.512996  \n",
       "25%            -0.459104  \n",
       "50%            -0.302986  \n",
       "75%             0.075082  \n",
       "max            10.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# push in any outlier values\n",
    "cols = X.columns\n",
    "X.loc[:,cols] = X[cols].clip(upper=Clip)\n",
    "X.loc[:,cols] = X[cols].clip(lower=-1*Clip)\n",
    "# X = (X_no_scaling - X_no_scaling.mean()) / X_no_scaling.std()\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# separate data into modeling (traintest) and out of time\n",
    "oot_recnum = 84300\n",
    "X_trntst = X[0:oot_recnum] \n",
    "Y_trntst = Y_save[0:oot_recnum]\n",
    "X_oot = X[oot_recnum:]\n",
    "Y_oot = Y_save[oot_recnum:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "niter = 0\n",
    "nitermax = 10\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "X_oot_orig = X_oot.copy()\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models. You can comment out any of these cells and just explore one model type. You can also just rerun that single cell multiple times as you explore different model hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5990180032733224 0.6264591439688716 0.3407821229050279\n",
      "1 0.5891980360065466 0.5797665369649806 0.3463687150837989\n",
      "2 0.6213114754098361 0.5813953488372093 0.3463687150837989\n",
      "3 0.5959595959595959 0.6094890510948905 0.3463687150837989\n",
      "4 0.6174957118353345 0.5473684210526316 0.35195530726256985\n",
      "5 0.6032786885245902 0.5465116279069767 0.35195530726256985\n",
      "6 0.5896147403685092 0.6273062730627307 0.3407821229050279\n",
      "7 0.610223642172524 0.5909090909090909 0.3463687150837989\n",
      "8 0.5852459016393443 0.6124031007751938 0.3407821229050279\n",
      "9 0.6063651591289783 0.5830258302583026 0.3463687150837989\n",
      "trn    0.601771\n",
      "tst    0.590463\n",
      "oot    0.345810\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "##### %%time\n",
    "# Logistic regression\n",
    "\n",
    "for niter in range(nitermax):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = LogisticRegression(penalty = 'l1', solver = 'saga', C = 0.1, max_iter = 3000) # C = 1, l1_ratio = 0.2\n",
    " \n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    \n",
    "print(FDR3.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8077544426494345 0.6907630522088354 0.49162011173184356\n",
      "1 0.8033057851239669 0.6958174904942965 0.5195530726256983\n",
      "2 0.8197573656845754 0.7079037800687286 0.5139664804469274\n",
      "3 0.8069883527454242 0.7378277153558053 0.49162011173184356\n",
      "4 0.7893030794165316 0.7450199203187251 0.49162011173184356\n",
      "5 0.805414551607445 0.703971119133574 0.4860335195530726\n",
      "6 0.8198653198653199 0.6715328467153284 0.5027932960893855\n",
      "7 0.8186356073211315 0.7378277153558053 0.5307262569832403\n",
      "8 0.8196994991652755 0.7137546468401487 0.46368715083798884\n",
      "9 0.7783094098883573 0.7759336099585062 0.5418994413407822\n",
      "trn    0.806903\n",
      "tst    0.718035\n",
      "oot    0.503352\n",
      "dtype: float64\n",
      "CPU times: user 9.48 s, sys: 83.3 ms, total: 9.57 s\n",
      "Wall time: 9.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Single DT\n",
    "\n",
    "for niter in range(nitermax):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = DecisionTreeClassifier(criterion = 'entropy', 8max_depth = 20, min_samples_split = 200,\\\n",
    "                                   min_samples_leaf = 60) #  splitter = 'best',\n",
    " \n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    \n",
    "print(FDR3.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7721518987341772 0.7245762711864406 0.5642458100558659\n",
      "1 0.7728706624605678 0.7435897435897436 0.5586592178770949\n",
      "2 0.7660626029654036 0.7241379310344828 0.547486033519553\n",
      "3 0.7841845140032949 0.7318007662835249 0.5698324022346368\n",
      "4 0.7728758169934641 0.70703125 0.553072625698324\n",
      "5 0.7708674304418985 0.7276264591439688 0.547486033519553\n",
      "6 0.7704654895666132 0.746938775510204 0.5698324022346368\n",
      "7 0.7836538461538461 0.7131147540983607 0.5586592178770949\n",
      "8 0.762063227953411 0.7715355805243446 0.5810055865921788\n",
      "9 0.7808896210873146 0.7547892720306514 0.5698324022346368\n",
      "trn    0.773609\n",
      "tst    0.734514\n",
      "oot    0.562011\n",
      "dtype: float64\n",
      "CPU times: user 2min 22s, sys: 939 ms, total: 2min 23s\n",
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# RF\n",
    "\n",
    "for niter in range(nitermax):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators = 100, max_depth = None, min_samples_split = 100, \\\n",
    "                                   min_samples_leaf = 100, max_features = None) # criterion = 'entropy', \n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted'] = predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted'] = predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    \n",
    "print(FDR3.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9226890756302522 0.7838827838827839 0.5698324022346368\n",
      "1 0.8852459016393442 0.8372093023255814 0.4301675977653631\n",
      "2 0.8920265780730897 0.7894736842105263 0.4972067039106145\n",
      "3 0.8904991948470209 0.7975708502024291 0.5307262569832403\n",
      "4 0.8867924528301887 0.8275862068965517 0.5307262569832403\n",
      "5 0.8948247078464107 0.8438661710037175 0.5642458100558659\n",
      "6 0.8930921052631579 0.8 0.4748603351955307\n",
      "7 0.8865478119935171 0.8645418326693227 0.4860335195530726\n",
      "8 0.8983333333333333 0.7947761194029851 0.547486033519553\n",
      "9 0.8958677685950414 0.8174904942965779 0.5418994413407822\n",
      "trn    0.894592\n",
      "tst    0.815640\n",
      "oot    0.517318\n",
      "dtype: float64\n",
      "CPU times: user 4min 16s, sys: 52.2 s, total: 5min 8s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# BT, light gradient boosting machine\n",
    "\n",
    "for niter in range(nitermax):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = lgb.LGBMClassifier(num_leaves = 50, max_depth = 4, n_estimators = 1000, learning_rate = 0.01, \\\n",
    "                               min_child_samples = 60) # , subsample=0.7\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    \n",
    "print(FDR3.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8223350253807107 0.7509025270758123 0.547486033519553\n",
      "1 0.8311036789297659 0.7555555555555555 0.5586592178770949\n",
      "2 0.8073089700996677 0.8007518796992481 0.5418994413407822\n",
      "3 0.8213716108452951 0.7551867219917012 0.5642458100558659\n",
      "4 0.8088962108731467 0.789272030651341 0.5586592178770949\n",
      "5 0.8 0.7747035573122529 0.4692737430167598\n",
      "6 0.8108974358974359 0.7581967213114754 0.5810055865921788\n",
      "7 0.8064 0.7983539094650206 0.553072625698324\n",
      "8 0.8071065989847716 0.7689530685920578 0.5195530726256983\n",
      "9 0.8298555377207063 0.7387755102040816 0.5698324022346368\n",
      "trn    0.814528\n",
      "tst    0.769065\n",
      "oot    0.546369\n",
      "dtype: float64\n",
      "CPU times: user 16min 8s, sys: 1min 33s, total: 17min 42s\n",
      "Wall time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# BT, extreme gradient boosting\n",
    "\n",
    "for niter in range(nitermax):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = xgb.XGBClassifier(n_estimators = 500, max_depth = 5, max_leaves = 0, learning_rate = 0.01, \\\n",
    "                              objective='binary:logistic', min_child_weight = 7, eval_metric = 'error')\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    \n",
    "print(FDR3.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7669902912621359 0.736 0.6033519553072626\n",
      "1 0.7483333333333333 0.7089552238805971 0.5865921787709497\n",
      "2 0.7549668874172185 0.7613636363636364 0.6089385474860335\n",
      "3 0.7277147487844409 0.7370517928286853 0.5810055865921788\n",
      "4 0.7557377049180328 0.7093023255813954 0.6145251396648045\n",
      "5 0.7768729641693811 0.7007874015748031 0.5977653631284916\n",
      "6 0.7401315789473685 0.7230769230769231 0.6033519553072626\n",
      "7 0.7470489038785835 0.7490909090909091 0.6033519553072626\n",
      "8 0.7692307692307693 0.7359307359307359 0.5810055865921788\n",
      "9 0.7726523887973641 0.7279693486590039 0.5698324022346368\n",
      "trn    0.755968\n",
      "tst    0.728953\n",
      "oot    0.594972\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "##### %%time\n",
    "# NN\n",
    "\n",
    "for niter in range(nitermax):  \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = MLPClassifier(hidden_layer_sizes=(20, 20), activation = 'tanh', alpha = 0.00001) \n",
    "    # solver = 'lbfgs', max_iter = 1000, learning_rate ='invscaling' \n",
    "    # learning_rate_init = 0.0001, shuffle = False\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    \n",
    "print(FDR3.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.7605177993527508 0.736 0.6033519553072626\n"
     ]
    }
   ],
   "source": [
    "X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(20, 20), activation = 'tanh', alpha = 0.00001) \n",
    "\n",
    "X_oot = X_oot_orig.copy()\n",
    "X_trn_save = X_trn.copy()\n",
    "Y_trn_save = Y_trn.copy()\n",
    "\n",
    "model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "X_trn['predicted'] = predictions\n",
    "X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "topRows = int(round(X_trn.shape[0]*0.03))\n",
    "temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "needed = temp.loc[:,'Fraud']\n",
    "FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "predictions = model.predict_proba(X_tst)[:,1]\n",
    "X_tst['predicted']=predictions\n",
    "X_tst['Fraud'] = Y_tst['Fraud']\n",
    "topRows = int(round(X_tst.shape[0]*0.03))\n",
    "temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "needed = temp.loc[:,'Fraud']\n",
    "FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "predictions = model.predict_proba(X_oot)[:,1]\n",
    "X_oot['predicted']=predictions\n",
    "X_oot['Fraud'] = Y_oot['Fraud']\n",
    "topRows = int(round(X_oot.shape[0]*0.03))\n",
    "temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "needed = temp.loc[:,'Fraud']\n",
    "FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn_new = X_trn.copy()\n",
    "X_tst_new = X_tst.copy()\n",
    "X_oot_new = X_oot.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cascade model\n",
    "\n",
    "### filter out extreme values in the training data based on predicted score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_sorted = X_trn_new.sort_values('predicted',ascending=False)\n",
    "trn_filter_extreme = trn_sorted.loc[trn_sorted['predicted']<0.9]\n",
    "trn_filter_extreme.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62516</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62640</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37559</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40288</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68997</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Fraud\n",
       "62516      1\n",
       "62640      1\n",
       "37559      1\n",
       "40288      1\n",
       "68997      1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# record_save = vars['Recnum']\n",
    "Y_trn_filter_extreme = pd.DataFrame(trn_filter_extreme.loc[:,'Fraud'])\n",
    "Y_trn_filter_extreme.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_filter_extreme.drop(['predicted', 'Fraud'], axis = 1, inplace = True)\n",
    "trn_filter_extreme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tst_new_var = pd.DataFrame(X_tst_new.iloc[:,0:15])\n",
    "X_tst_new_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26044</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47480</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16831</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38765</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14372</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Fraud\n",
       "26044      0\n",
       "47480      0\n",
       "16831      0\n",
       "38765      0\n",
       "14372      0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_tst_new = pd.DataFrame(X_tst_new.loc[:,'Fraud'])\n",
    "Y_tst_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7136465324384788 0.716 0.5810055865921788\n",
      "1 0.6845637583892618 0.648 0.6089385474860335\n",
      "2 0.70917225950783 0.72 0.5810055865921788\n",
      "3 0.7293064876957495 0.716 0.441340782122905\n",
      "4 0.727069351230425 0.712 0.4692737430167598\n",
      "5 0.7181208053691275 0.72 0.5642458100558659\n",
      "6 0.7785234899328859 0.7 0.2849162011173184\n",
      "7 0.7315436241610739 0.708 0.5642458100558659\n",
      "8 0.7136465324384788 0.72 0.5363128491620112\n",
      "9 0.7203579418344519 0.692 0.45251396648044695\n",
      "trn    0.722595\n",
      "tst    0.705200\n",
      "oot    0.508380\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for niter in range(nitermax):  \n",
    "\n",
    "    model = MLPClassifier(hidden_layer_sizes=(30, 30), activation = 'tanh', alpha = 0.0001) \n",
    "    # solver = 'lbfgs', max_iter = 1000, learning_rate ='invscaling' \n",
    "    # learning_rate_init = 0.0001, shuffle = False\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = trn_filter_extreme.copy()\n",
    "    Y_trn_save = Y_trn_filter_extreme.copy()\n",
    "    \n",
    "    X_tst_save = X_tst_new_var.copy()\n",
    "    Y_tst_save = Y_tst_new.copy()\n",
    "    \n",
    "    model.fit(X_trn_save, Y_trn_save.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn_save['predicted'] = predictions\n",
    "    X_trn_save['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn_save.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn_save.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst_save)[:,1]\n",
    "    X_tst_save['predicted']=predictions\n",
    "    X_tst_save['Fraud'] = Y_tst_save['Fraud']\n",
    "    topRows = int(round(X_tst_save.shape[0]*0.03))\n",
    "    temp = X_tst_save.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst_save.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    \n",
    "print(FDR3.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cascade model\n",
    "\n",
    "### filter out intermediate values in the training data based on predicted score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_sorted = X_trn_new.sort_values('predicted',ascending=False)\n",
    "trn_filter_med = trn_sorted.loc[(trn_sorted['predicted']<=0.004)&(trn_sorted['predicted']>=0.0003)]\n",
    "trn_filter_med.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67636</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83726</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67350</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21691</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22914</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Fraud\n",
       "67636      0\n",
       "83726      0\n",
       "67350      0\n",
       "21691      0\n",
       "22914      0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_trn_filter_med = pd.DataFrame(trn_filter_med.loc[:,'Fraud'])\n",
    "Y_trn_filter_med.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_filter_med.drop(['predicted', 'Fraud'], axis = 1, inplace = True)\n",
    "trn_filter_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.17857142857142858 0.424 0.30726256983240224\n",
      "1 0.10714285714285714 0.396 0.31843575418994413\n",
      "2 0.10714285714285714 0.456 0.33519553072625696\n",
      "3 0.14285714285714285 0.412 0.31843575418994413\n",
      "4 0.14285714285714285 0.416 0.3240223463687151\n",
      "5 0.14285714285714285 0.432 0.2737430167597765\n",
      "6 0.14285714285714285 0.468 0.29608938547486036\n",
      "7 0.10714285714285714 0.416 0.329608938547486\n",
      "8 0.10714285714285714 0.444 0.26256983240223464\n",
      "9 0.14285714285714285 0.432 0.3016759776536313\n",
      "trn    0.132143\n",
      "tst    0.429600\n",
      "oot    0.306704\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for niter in range(nitermax):  \n",
    "\n",
    "    model = MLPClassifier(hidden_layer_sizes=(20, 20), activation = 'tanh', alpha = 0.00001) \n",
    "    # solver = 'lbfgs', max_iter = 1000, learning_rate ='invscaling' \n",
    "    # learning_rate_init = 0.0001, shuffle = False\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = trn_filter_med.copy()\n",
    "    Y_trn_save = Y_trn_filter_med.copy()\n",
    "    \n",
    "    X_tst_save = X_tst_new_var.copy()\n",
    "    Y_tst_save = Y_tst_new.copy()\n",
    "    \n",
    "    model.fit(X_trn_save, Y_trn_save.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn_save['predicted'] = predictions\n",
    "    X_trn_save['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn_save.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn_save.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst_save)[:,1]\n",
    "    X_tst_save['predicted']=predictions\n",
    "    X_tst_save['Fraud'] = Y_tst_save['Fraud']\n",
    "    topRows = int(round(X_tst_save.shape[0]*0.03))\n",
    "    temp = X_tst_save.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst_save.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    \n",
    "print(FDR3.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration:  0:10:19.196501\n"
     ]
    }
   ],
   "source": [
    "print('duration: ', datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The rest of the notebook makes the tables for your final model of choice. You need to run that final model only once (no CV). If you want you can run the below cell over and over by itself until it gives you a model you like. But you can't change from your best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7364217252396166 0.7322834645669292 0.6256983240223464\n"
     ]
    }
   ],
   "source": [
    "X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "# here's where you put your final model of choice\n",
    "model = MLPClassifier(hidden_layer_sizes=(20, 20), activation = 'tanh', alpha = 0.00001) \n",
    "\n",
    "X_oot = X_oot_orig.copy()\n",
    "X_trn_save = X_trn.copy()\n",
    "Y_trn_save = Y_trn.copy()\n",
    "\n",
    "model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "X_trn['predicted'] = predictions\n",
    "X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "topRows = int(round(X_trn.shape[0]*0.03))\n",
    "temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "needed = temp.loc[:,'Fraud']\n",
    "FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "predictions = model.predict_proba(X_tst)[:,1]\n",
    "X_tst['predicted']=predictions\n",
    "X_tst['Fraud'] = Y_tst['Fraud']\n",
    "topRows = int(round(X_tst.shape[0]*0.03))\n",
    "temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "needed = temp.loc[:,'Fraud']\n",
    "FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "predictions = model.predict_proba(X_oot)[:,1]\n",
    "X_oot['predicted']=predictions\n",
    "X_oot['Fraud'] = Y_oot['Fraud']\n",
    "topRows = int(round(X_oot.shape[0]*0.03))\n",
    "temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "needed = temp.loc[:,'Fraud']\n",
    "FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn_eval = X_trn.copy()\n",
    "X_tst_eval = X_tst.copy()\n",
    "X_oot_eval = X_oot.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_zip_total_3</th>\n",
       "      <th>card_state_max_30</th>\n",
       "      <th>card_zip_total_14</th>\n",
       "      <th>card_merch_total_0</th>\n",
       "      <th>card_state_total_0</th>\n",
       "      <th>card_zip_total_0</th>\n",
       "      <th>merch_zip_avg_0</th>\n",
       "      <th>merch_dow_avg_3</th>\n",
       "      <th>Merchnum_avg_0</th>\n",
       "      <th>merch_dow_avg_1</th>\n",
       "      <th>merch_dow_avg_0</th>\n",
       "      <th>merch_zip_avg_1</th>\n",
       "      <th>merch_state_avg_0</th>\n",
       "      <th>Merchnum_avg_1</th>\n",
       "      <th>card_merch_avg_30</th>\n",
       "      <th>predicted</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89183</th>\n",
       "      <td>9.996093</td>\n",
       "      <td>5.843897</td>\n",
       "      <td>9.670017</td>\n",
       "      <td>6.908379</td>\n",
       "      <td>6.850649</td>\n",
       "      <td>6.904608</td>\n",
       "      <td>1.233234</td>\n",
       "      <td>1.259426</td>\n",
       "      <td>1.259426</td>\n",
       "      <td>1.259426</td>\n",
       "      <td>1.259426</td>\n",
       "      <td>1.249116</td>\n",
       "      <td>1.232879</td>\n",
       "      <td>1.276556</td>\n",
       "      <td>1.177569</td>\n",
       "      <td>0.999156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89186</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.843897</td>\n",
       "      <td>9.716424</td>\n",
       "      <td>6.982482</td>\n",
       "      <td>6.924233</td>\n",
       "      <td>6.978681</td>\n",
       "      <td>1.133368</td>\n",
       "      <td>1.157413</td>\n",
       "      <td>1.157413</td>\n",
       "      <td>1.157413</td>\n",
       "      <td>1.157413</td>\n",
       "      <td>1.201604</td>\n",
       "      <td>1.133031</td>\n",
       "      <td>1.227966</td>\n",
       "      <td>1.132444</td>\n",
       "      <td>0.999144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89174</th>\n",
       "      <td>9.579341</td>\n",
       "      <td>5.843897</td>\n",
       "      <td>9.265221</td>\n",
       "      <td>6.261996</td>\n",
       "      <td>6.208785</td>\n",
       "      <td>6.258480</td>\n",
       "      <td>1.196437</td>\n",
       "      <td>1.221838</td>\n",
       "      <td>1.221838</td>\n",
       "      <td>1.221838</td>\n",
       "      <td>1.221838</td>\n",
       "      <td>1.232957</td>\n",
       "      <td>1.196089</td>\n",
       "      <td>1.260030</td>\n",
       "      <td>1.162222</td>\n",
       "      <td>0.998513</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89134</th>\n",
       "      <td>9.444795</td>\n",
       "      <td>5.843897</td>\n",
       "      <td>9.134536</td>\n",
       "      <td>6.053316</td>\n",
       "      <td>6.001564</td>\n",
       "      <td>6.049882</td>\n",
       "      <td>1.279474</td>\n",
       "      <td>1.306660</td>\n",
       "      <td>1.306660</td>\n",
       "      <td>1.306660</td>\n",
       "      <td>1.306660</td>\n",
       "      <td>1.268566</td>\n",
       "      <td>1.279110</td>\n",
       "      <td>1.296448</td>\n",
       "      <td>1.196043</td>\n",
       "      <td>0.998291</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89130</th>\n",
       "      <td>9.371485</td>\n",
       "      <td>5.843897</td>\n",
       "      <td>9.063329</td>\n",
       "      <td>5.939611</td>\n",
       "      <td>5.888654</td>\n",
       "      <td>5.936223</td>\n",
       "      <td>1.407425</td>\n",
       "      <td>1.437362</td>\n",
       "      <td>1.437362</td>\n",
       "      <td>1.437362</td>\n",
       "      <td>1.437362</td>\n",
       "      <td>1.318605</td>\n",
       "      <td>1.407038</td>\n",
       "      <td>1.347622</td>\n",
       "      <td>1.243567</td>\n",
       "      <td>0.998257</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89114</th>\n",
       "      <td>6.531345</td>\n",
       "      <td>2.242003</td>\n",
       "      <td>6.304671</td>\n",
       "      <td>1.534554</td>\n",
       "      <td>1.514395</td>\n",
       "      <td>1.532905</td>\n",
       "      <td>0.678600</td>\n",
       "      <td>0.692869</td>\n",
       "      <td>0.692869</td>\n",
       "      <td>0.692869</td>\n",
       "      <td>0.692869</td>\n",
       "      <td>1.121454</td>\n",
       "      <td>0.678348</td>\n",
       "      <td>1.145997</td>\n",
       "      <td>1.056321</td>\n",
       "      <td>0.993245</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89117</th>\n",
       "      <td>6.633029</td>\n",
       "      <td>2.242003</td>\n",
       "      <td>6.403438</td>\n",
       "      <td>1.692266</td>\n",
       "      <td>1.671005</td>\n",
       "      <td>1.690555</td>\n",
       "      <td>0.569497</td>\n",
       "      <td>0.581421</td>\n",
       "      <td>0.581421</td>\n",
       "      <td>0.581421</td>\n",
       "      <td>0.581421</td>\n",
       "      <td>1.073638</td>\n",
       "      <td>0.569266</td>\n",
       "      <td>1.097096</td>\n",
       "      <td>1.010908</td>\n",
       "      <td>0.989613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89091</th>\n",
       "      <td>5.900186</td>\n",
       "      <td>2.242003</td>\n",
       "      <td>5.691619</td>\n",
       "      <td>0.555626</td>\n",
       "      <td>0.542311</td>\n",
       "      <td>0.554363</td>\n",
       "      <td>0.351215</td>\n",
       "      <td>0.358446</td>\n",
       "      <td>0.358446</td>\n",
       "      <td>0.358446</td>\n",
       "      <td>0.358446</td>\n",
       "      <td>1.115191</td>\n",
       "      <td>0.351025</td>\n",
       "      <td>1.139592</td>\n",
       "      <td>1.050374</td>\n",
       "      <td>0.988311</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89120</th>\n",
       "      <td>6.720243</td>\n",
       "      <td>2.242003</td>\n",
       "      <td>6.488149</td>\n",
       "      <td>1.827534</td>\n",
       "      <td>1.805327</td>\n",
       "      <td>1.825769</td>\n",
       "      <td>0.480494</td>\n",
       "      <td>0.490504</td>\n",
       "      <td>0.490504</td>\n",
       "      <td>0.490504</td>\n",
       "      <td>0.490504</td>\n",
       "      <td>1.026530</td>\n",
       "      <td>0.480280</td>\n",
       "      <td>1.048919</td>\n",
       "      <td>0.966167</td>\n",
       "      <td>0.983065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89112</th>\n",
       "      <td>6.015131</td>\n",
       "      <td>2.242003</td>\n",
       "      <td>5.803267</td>\n",
       "      <td>0.733906</td>\n",
       "      <td>0.719345</td>\n",
       "      <td>0.732573</td>\n",
       "      <td>0.287165</td>\n",
       "      <td>0.293020</td>\n",
       "      <td>0.293020</td>\n",
       "      <td>0.293020</td>\n",
       "      <td>0.293020</td>\n",
       "      <td>1.066552</td>\n",
       "      <td>0.286987</td>\n",
       "      <td>1.089849</td>\n",
       "      <td>1.004178</td>\n",
       "      <td>0.981640</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89121</th>\n",
       "      <td>7.123633</td>\n",
       "      <td>2.242003</td>\n",
       "      <td>6.879966</td>\n",
       "      <td>2.453193</td>\n",
       "      <td>2.426612</td>\n",
       "      <td>2.451181</td>\n",
       "      <td>0.625435</td>\n",
       "      <td>0.638561</td>\n",
       "      <td>0.638561</td>\n",
       "      <td>0.638561</td>\n",
       "      <td>0.638561</td>\n",
       "      <td>1.051920</td>\n",
       "      <td>0.625193</td>\n",
       "      <td>1.074884</td>\n",
       "      <td>0.990281</td>\n",
       "      <td>0.980881</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89128</th>\n",
       "      <td>7.238920</td>\n",
       "      <td>2.242003</td>\n",
       "      <td>6.991946</td>\n",
       "      <td>2.632004</td>\n",
       "      <td>2.604172</td>\n",
       "      <td>2.629921</td>\n",
       "      <td>0.566703</td>\n",
       "      <td>0.578566</td>\n",
       "      <td>0.578566</td>\n",
       "      <td>0.578566</td>\n",
       "      <td>0.578566</td>\n",
       "      <td>1.015139</td>\n",
       "      <td>0.566472</td>\n",
       "      <td>1.037269</td>\n",
       "      <td>0.955348</td>\n",
       "      <td>0.971493</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89129</th>\n",
       "      <td>7.331398</td>\n",
       "      <td>2.242003</td>\n",
       "      <td>7.081771</td>\n",
       "      <td>2.775437</td>\n",
       "      <td>2.746602</td>\n",
       "      <td>2.773298</td>\n",
       "      <td>0.507500</td>\n",
       "      <td>0.518091</td>\n",
       "      <td>0.518091</td>\n",
       "      <td>0.518091</td>\n",
       "      <td>0.518091</td>\n",
       "      <td>0.976491</td>\n",
       "      <td>0.507280</td>\n",
       "      <td>0.997744</td>\n",
       "      <td>0.918643</td>\n",
       "      <td>0.957720</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89077</th>\n",
       "      <td>5.411856</td>\n",
       "      <td>2.242003</td>\n",
       "      <td>5.217299</td>\n",
       "      <td>8.436915</td>\n",
       "      <td>8.368498</td>\n",
       "      <td>8.432540</td>\n",
       "      <td>1.234236</td>\n",
       "      <td>1.260449</td>\n",
       "      <td>1.260449</td>\n",
       "      <td>1.260449</td>\n",
       "      <td>1.260449</td>\n",
       "      <td>1.153316</td>\n",
       "      <td>1.233880</td>\n",
       "      <td>1.178582</td>\n",
       "      <td>1.178005</td>\n",
       "      <td>0.956808</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95844</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.954088</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89075</th>\n",
       "      <td>5.282020</td>\n",
       "      <td>2.242003</td>\n",
       "      <td>5.091188</td>\n",
       "      <td>8.235538</td>\n",
       "      <td>8.168529</td>\n",
       "      <td>8.231243</td>\n",
       "      <td>1.300452</td>\n",
       "      <td>1.328089</td>\n",
       "      <td>1.328089</td>\n",
       "      <td>1.328089</td>\n",
       "      <td>1.328089</td>\n",
       "      <td>1.210882</td>\n",
       "      <td>1.300084</td>\n",
       "      <td>1.237455</td>\n",
       "      <td>1.241810</td>\n",
       "      <td>0.953582</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89074</th>\n",
       "      <td>5.163020</td>\n",
       "      <td>2.242003</td>\n",
       "      <td>4.975602</td>\n",
       "      <td>8.050969</td>\n",
       "      <td>7.985250</td>\n",
       "      <td>8.046747</td>\n",
       "      <td>1.379366</td>\n",
       "      <td>1.408700</td>\n",
       "      <td>1.408700</td>\n",
       "      <td>1.408700</td>\n",
       "      <td>1.408700</td>\n",
       "      <td>1.279326</td>\n",
       "      <td>1.378984</td>\n",
       "      <td>1.307452</td>\n",
       "      <td>1.317852</td>\n",
       "      <td>0.949945</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89068</th>\n",
       "      <td>4.433260</td>\n",
       "      <td>2.242003</td>\n",
       "      <td>4.266778</td>\n",
       "      <td>6.919111</td>\n",
       "      <td>6.861306</td>\n",
       "      <td>6.915336</td>\n",
       "      <td>1.235881</td>\n",
       "      <td>1.262130</td>\n",
       "      <td>1.262130</td>\n",
       "      <td>1.262130</td>\n",
       "      <td>1.262130</td>\n",
       "      <td>1.135622</td>\n",
       "      <td>1.235526</td>\n",
       "      <td>1.160487</td>\n",
       "      <td>1.179591</td>\n",
       "      <td>0.939377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95146</th>\n",
       "      <td>2.112616</td>\n",
       "      <td>4.259603</td>\n",
       "      <td>2.452577</td>\n",
       "      <td>0.070022</td>\n",
       "      <td>0.060102</td>\n",
       "      <td>0.068951</td>\n",
       "      <td>-0.051351</td>\n",
       "      <td>-0.052774</td>\n",
       "      <td>-0.052774</td>\n",
       "      <td>-0.052774</td>\n",
       "      <td>-0.052774</td>\n",
       "      <td>-0.054745</td>\n",
       "      <td>-0.051466</td>\n",
       "      <td>-0.056897</td>\n",
       "      <td>-0.114873</td>\n",
       "      <td>0.934443</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94884</th>\n",
       "      <td>1.994720</td>\n",
       "      <td>4.259603</td>\n",
       "      <td>2.338064</td>\n",
       "      <td>-0.112835</td>\n",
       "      <td>-0.121476</td>\n",
       "      <td>-0.113834</td>\n",
       "      <td>-0.213523</td>\n",
       "      <td>-0.218433</td>\n",
       "      <td>-0.218433</td>\n",
       "      <td>-0.218433</td>\n",
       "      <td>-0.218433</td>\n",
       "      <td>-0.219280</td>\n",
       "      <td>-0.213608</td>\n",
       "      <td>-0.225167</td>\n",
       "      <td>-0.220055</td>\n",
       "      <td>0.928213</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       card_zip_total_3  card_state_max_30  card_zip_total_14  \\\n",
       "89183          9.996093           5.843897           9.670017   \n",
       "89186         10.000000           5.843897           9.716424   \n",
       "89174          9.579341           5.843897           9.265221   \n",
       "89134          9.444795           5.843897           9.134536   \n",
       "89130          9.371485           5.843897           9.063329   \n",
       "89114          6.531345           2.242003           6.304671   \n",
       "89117          6.633029           2.242003           6.403438   \n",
       "89091          5.900186           2.242003           5.691619   \n",
       "89120          6.720243           2.242003           6.488149   \n",
       "89112          6.015131           2.242003           5.803267   \n",
       "89121          7.123633           2.242003           6.879966   \n",
       "89128          7.238920           2.242003           6.991946   \n",
       "89129          7.331398           2.242003           7.081771   \n",
       "89077          5.411856           2.242003           5.217299   \n",
       "95844         10.000000          10.000000          10.000000   \n",
       "89075          5.282020           2.242003           5.091188   \n",
       "89074          5.163020           2.242003           4.975602   \n",
       "89068          4.433260           2.242003           4.266778   \n",
       "95146          2.112616           4.259603           2.452577   \n",
       "94884          1.994720           4.259603           2.338064   \n",
       "\n",
       "       card_merch_total_0  card_state_total_0  card_zip_total_0  \\\n",
       "89183            6.908379            6.850649          6.904608   \n",
       "89186            6.982482            6.924233          6.978681   \n",
       "89174            6.261996            6.208785          6.258480   \n",
       "89134            6.053316            6.001564          6.049882   \n",
       "89130            5.939611            5.888654          5.936223   \n",
       "89114            1.534554            1.514395          1.532905   \n",
       "89117            1.692266            1.671005          1.690555   \n",
       "89091            0.555626            0.542311          0.554363   \n",
       "89120            1.827534            1.805327          1.825769   \n",
       "89112            0.733906            0.719345          0.732573   \n",
       "89121            2.453193            2.426612          2.451181   \n",
       "89128            2.632004            2.604172          2.629921   \n",
       "89129            2.775437            2.746602          2.773298   \n",
       "89077            8.436915            8.368498          8.432540   \n",
       "95844           10.000000           10.000000         10.000000   \n",
       "89075            8.235538            8.168529          8.231243   \n",
       "89074            8.050969            7.985250          8.046747   \n",
       "89068            6.919111            6.861306          6.915336   \n",
       "95146            0.070022            0.060102          0.068951   \n",
       "94884           -0.112835           -0.121476         -0.113834   \n",
       "\n",
       "       merch_zip_avg_0  merch_dow_avg_3  Merchnum_avg_0  merch_dow_avg_1  \\\n",
       "89183         1.233234         1.259426        1.259426         1.259426   \n",
       "89186         1.133368         1.157413        1.157413         1.157413   \n",
       "89174         1.196437         1.221838        1.221838         1.221838   \n",
       "89134         1.279474         1.306660        1.306660         1.306660   \n",
       "89130         1.407425         1.437362        1.437362         1.437362   \n",
       "89114         0.678600         0.692869        0.692869         0.692869   \n",
       "89117         0.569497         0.581421        0.581421         0.581421   \n",
       "89091         0.351215         0.358446        0.358446         0.358446   \n",
       "89120         0.480494         0.490504        0.490504         0.490504   \n",
       "89112         0.287165         0.293020        0.293020         0.293020   \n",
       "89121         0.625435         0.638561        0.638561         0.638561   \n",
       "89128         0.566703         0.578566        0.578566         0.578566   \n",
       "89129         0.507500         0.518091        0.518091         0.518091   \n",
       "89077         1.234236         1.260449        1.260449         1.260449   \n",
       "95844        10.000000        10.000000       10.000000        10.000000   \n",
       "89075         1.300452         1.328089        1.328089         1.328089   \n",
       "89074         1.379366         1.408700        1.408700         1.408700   \n",
       "89068         1.235881         1.262130        1.262130         1.262130   \n",
       "95146        -0.051351        -0.052774       -0.052774        -0.052774   \n",
       "94884        -0.213523        -0.218433       -0.218433        -0.218433   \n",
       "\n",
       "       merch_dow_avg_0  merch_zip_avg_1  merch_state_avg_0  Merchnum_avg_1  \\\n",
       "89183         1.259426         1.249116           1.232879        1.276556   \n",
       "89186         1.157413         1.201604           1.133031        1.227966   \n",
       "89174         1.221838         1.232957           1.196089        1.260030   \n",
       "89134         1.306660         1.268566           1.279110        1.296448   \n",
       "89130         1.437362         1.318605           1.407038        1.347622   \n",
       "89114         0.692869         1.121454           0.678348        1.145997   \n",
       "89117         0.581421         1.073638           0.569266        1.097096   \n",
       "89091         0.358446         1.115191           0.351025        1.139592   \n",
       "89120         0.490504         1.026530           0.480280        1.048919   \n",
       "89112         0.293020         1.066552           0.286987        1.089849   \n",
       "89121         0.638561         1.051920           0.625193        1.074884   \n",
       "89128         0.578566         1.015139           0.566472        1.037269   \n",
       "89129         0.518091         0.976491           0.507280        0.997744   \n",
       "89077         1.260449         1.153316           1.233880        1.178582   \n",
       "95844        10.000000        10.000000          10.000000       10.000000   \n",
       "89075         1.328089         1.210882           1.300084        1.237455   \n",
       "89074         1.408700         1.279326           1.378984        1.307452   \n",
       "89068         1.262130         1.135622           1.235526        1.160487   \n",
       "95146        -0.052774        -0.054745          -0.051466       -0.056897   \n",
       "94884        -0.218433        -0.219280          -0.213608       -0.225167   \n",
       "\n",
       "       card_merch_avg_30  predicted  Fraud  \n",
       "89183           1.177569   0.999156      1  \n",
       "89186           1.132444   0.999144      1  \n",
       "89174           1.162222   0.998513      1  \n",
       "89134           1.196043   0.998291      1  \n",
       "89130           1.243567   0.998257      1  \n",
       "89114           1.056321   0.993245      1  \n",
       "89117           1.010908   0.989613      1  \n",
       "89091           1.050374   0.988311      1  \n",
       "89120           0.966167   0.983065      1  \n",
       "89112           1.004178   0.981640      1  \n",
       "89121           0.990281   0.980881      1  \n",
       "89128           0.955348   0.971493      1  \n",
       "89129           0.918643   0.957720      1  \n",
       "89077           1.178005   0.956808      1  \n",
       "95844          10.000000   0.954088      0  \n",
       "89075           1.241810   0.953582      1  \n",
       "89074           1.317852   0.949945      1  \n",
       "89068           1.179591   0.939377      1  \n",
       "95146          -0.114873   0.934443      1  \n",
       "94884          -0.220055   0.928213      1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['bin','#recs','#g','#b','%g','%b','tot','cg','cb','%cg','FDR','KS','FPR']\n",
    "FDR_trn = pd.DataFrame(np.zeros((101, 13)), columns = cols)\n",
    "FDR_tst = pd.DataFrame(np.zeros((101, 13)), columns = cols)\n",
    "FDR_oot = pd.DataFrame(np.zeros((101, 13)), columns = cols)\n",
    "trn_sorted = X_trn_eval.sort_values('predicted',ascending=False)\n",
    "tst_sorted = X_tst_eval.sort_values('predicted',ascending=False)\n",
    "oot_sorted = X_oot_eval.sort_values('predicted',ascending=False)\n",
    "bad_tot_trn = sum(X_trn_eval.loc[:, 'Fraud'])\n",
    "bad_tot_tst = sum(X_tst_eval.loc[:, 'Fraud'])\n",
    "bad_tot_oot = sum(X_oot_eval.loc[:, 'Fraud'])\n",
    "num_tot_trn = len(X_trn_eval)\n",
    "num_tot_tst = len(X_tst_eval)\n",
    "num_tot_oot = len(X_oot_eval)\n",
    "good_tot_trn = num_tot_trn - bad_tot_trn\n",
    "good_tot_tst = num_tot_tst - bad_tot_tst\n",
    "good_tot_oot = num_tot_oot - bad_tot_oot\n",
    "oot_sorted.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin</th>\n",
       "      <th>#recs</th>\n",
       "      <th>#g</th>\n",
       "      <th>#b</th>\n",
       "      <th>%g</th>\n",
       "      <th>%b</th>\n",
       "      <th>tot</th>\n",
       "      <th>cg</th>\n",
       "      <th>cb</th>\n",
       "      <th>%cg</th>\n",
       "      <th>FDR</th>\n",
       "      <th>KS</th>\n",
       "      <th>FPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>40.169492</td>\n",
       "      <td>59.830508</td>\n",
       "      <td>590.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>0.405933</td>\n",
       "      <td>56.389776</td>\n",
       "      <td>55.983843</td>\n",
       "      <td>0.671388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>507.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>85.932203</td>\n",
       "      <td>14.067797</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>744.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>1.274322</td>\n",
       "      <td>69.648562</td>\n",
       "      <td>68.374241</td>\n",
       "      <td>1.706422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>95.762712</td>\n",
       "      <td>4.237288</td>\n",
       "      <td>1770.0</td>\n",
       "      <td>1309.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>2.242053</td>\n",
       "      <td>73.642173</td>\n",
       "      <td>71.400120</td>\n",
       "      <td>2.839479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>95.932203</td>\n",
       "      <td>4.067797</td>\n",
       "      <td>2360.0</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>3.211496</td>\n",
       "      <td>77.476038</td>\n",
       "      <td>74.264542</td>\n",
       "      <td>3.865979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56650.0</td>\n",
       "      <td>56025.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>95.959509</td>\n",
       "      <td>99.840256</td>\n",
       "      <td>3.880746</td>\n",
       "      <td>89.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.830508</td>\n",
       "      <td>0.169492</td>\n",
       "      <td>57240.0</td>\n",
       "      <td>56614.0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>96.968347</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3.031653</td>\n",
       "      <td>90.437700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57830.0</td>\n",
       "      <td>57204.0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>97.978898</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.021102</td>\n",
       "      <td>91.380192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58420.0</td>\n",
       "      <td>57794.0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>98.989449</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.010551</td>\n",
       "      <td>92.322684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59010.0</td>\n",
       "      <td>58384.0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93.265176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bin  #recs     #g     #b          %g         %b      tot       cg  \\\n",
       "0      0.0    0.0    0.0    0.0    0.000000   0.000000      0.0      0.0   \n",
       "1      1.0  590.0  237.0  353.0   40.169492  59.830508    590.0    237.0   \n",
       "2      2.0  590.0  507.0   83.0   85.932203  14.067797   1180.0    744.0   \n",
       "3      3.0  590.0  565.0   25.0   95.762712   4.237288   1770.0   1309.0   \n",
       "4      4.0  590.0  566.0   24.0   95.932203   4.067797   2360.0   1875.0   \n",
       "..     ...    ...    ...    ...         ...        ...      ...      ...   \n",
       "96    96.0  590.0  590.0    0.0  100.000000   0.000000  56650.0  56025.0   \n",
       "97    97.0  590.0  589.0    1.0   99.830508   0.169492  57240.0  56614.0   \n",
       "98    98.0  590.0  590.0    0.0  100.000000   0.000000  57830.0  57204.0   \n",
       "99    99.0  590.0  590.0    0.0  100.000000   0.000000  58420.0  57794.0   \n",
       "100  100.0  590.0  590.0    0.0  100.000000   0.000000  59010.0  58384.0   \n",
       "\n",
       "        cb         %cg         FDR         KS        FPR  \n",
       "0      0.0    0.000000    0.000000   0.000000   0.000000  \n",
       "1    353.0    0.405933   56.389776  55.983843   0.671388  \n",
       "2    436.0    1.274322   69.648562  68.374241   1.706422  \n",
       "3    461.0    2.242053   73.642173  71.400120   2.839479  \n",
       "4    485.0    3.211496   77.476038  74.264542   3.865979  \n",
       "..     ...         ...         ...        ...        ...  \n",
       "96   625.0   95.959509   99.840256   3.880746  89.640000  \n",
       "97   626.0   96.968347  100.000000   3.031653  90.437700  \n",
       "98   626.0   97.978898  100.000000   2.021102  91.380192  \n",
       "99   626.0   98.989449  100.000000   1.010551  92.322684  \n",
       "100  626.0  100.000000  100.000000   0.000000  93.265176  \n",
       "\n",
       "[101 rows x 13 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(101):\n",
    "    percent_rows_trn = int(round(X_trn_eval.shape[0]*0.01*i))\n",
    "    percent_rows_tst = int(round(X_tst_eval.shape[0]*0.01*i))\n",
    "    percent_rows_oot = int(round(X_oot_eval.shape[0]*0.01*i))\n",
    "    temp_trn = trn_sorted.head(percent_rows_trn)\n",
    "    temp_tst = tst_sorted.head(percent_rows_tst)\n",
    "    temp_oot = oot_sorted.head(percent_rows_oot)\n",
    "    num_bad_trn = sum(temp_trn.loc[:,'Fraud'])\n",
    "    num_bad_tst = sum(temp_tst.loc[:,'Fraud'])\n",
    "    num_bad_oot = sum(temp_oot.loc[:,'Fraud'])\n",
    "    num_tot_trn = len(temp_trn)\n",
    "    num_tot_tst = len(temp_tst)\n",
    "    num_tot_oot = len(temp_oot)\n",
    "    num_good_trn = num_tot_trn - num_bad_trn\n",
    "    num_good_tst = num_tot_tst - num_bad_tst\n",
    "    num_good_oot = num_tot_oot - num_bad_oot\n",
    "    \n",
    "    FDR_trn.loc[i, 'bin'] = i\n",
    "    FDR_trn.loc[i,'#recs'] = 0\n",
    "    FDR_trn.loc[i, 'tot'] = num_tot_trn\n",
    "    FDR_trn.loc[i, 'cg'] = num_good_trn\n",
    "    FDR_trn.loc[i, 'cb'] = num_bad_trn\n",
    "    FDR_tst.loc[i, 'bin'] = i\n",
    "    FDR_tst.loc[i, 'tot'] = num_tot_tst\n",
    "    FDR_tst.loc[i, 'cg'] = num_good_tst\n",
    "    FDR_tst.loc[i, 'cb'] = num_bad_tst\n",
    "    FDR_oot.loc[i, 'bin'] = i\n",
    "    FDR_oot.loc[i, 'tot'] = num_tot_oot\n",
    "    FDR_oot.loc[i, 'cg'] = num_good_oot\n",
    "    FDR_oot.loc[i, 'cb'] = num_bad_oot\n",
    "    if i != 0:\n",
    "        FDR_trn.loc[i, '#g'] = num_good_trn - FDR_trn.loc[i-1, 'cg']\n",
    "        FDR_trn.loc[i, '#b'] = num_bad_trn - FDR_trn.loc[i-1, 'cb']\n",
    "        FDR_trn.loc[i,'#recs'] = FDR_trn.loc[i, '#g'] + FDR_trn.loc[i, '#b']\n",
    "        FDR_trn.loc[i, '%g'] = 100* (num_good_trn - FDR_trn.loc[i-1, 'cg']) / (num_tot_trn - FDR_trn.loc[i-1, 'tot'])\n",
    "        FDR_trn.loc[i, '%b'] = 100 - FDR_trn.loc[i, '%g']\n",
    "        FDR_trn.loc[i, '%cg'] = 100 * num_good_trn / good_tot_trn\n",
    "        FDR_trn.loc[i, 'FDR'] = 100 * num_bad_trn / bad_tot_trn\n",
    "        FDR_trn.loc[i, 'KS'] = FDR_trn.loc[i, 'FDR'] - FDR_trn.loc[i, '%cg']\n",
    "        FDR_trn.loc[i, 'FPR'] = num_good_trn / num_bad_trn\n",
    "        FDR_tst.loc[i, '#g'] = num_good_tst - FDR_tst.loc[i-1, 'cg']\n",
    "        FDR_tst.loc[i, '#b'] = num_bad_tst - FDR_tst.loc[i-1, 'cb']\n",
    "        FDR_tst.loc[i,'#recs'] = FDR_tst.loc[i, '#g'] + FDR_tst.loc[i, '#b']\n",
    "        FDR_tst.loc[i, '%g'] = 100* (num_good_tst - FDR_tst.loc[i-1, 'cg']) / (num_tot_tst - FDR_tst.loc[i-1, 'tot'])\n",
    "        FDR_tst.loc[i, '%b'] = 100 - FDR_tst.loc[i, '%g']\n",
    "        FDR_tst.loc[i, '%cg'] = 100 * num_good_tst / good_tot_tst\n",
    "        FDR_tst.loc[i, 'FDR'] = 100 * num_bad_tst / bad_tot_tst\n",
    "        FDR_tst.loc[i, 'KS'] = FDR_tst.loc[i, 'FDR'] - FDR_tst.loc[i, '%cg']\n",
    "        FDR_tst.loc[i, 'FPR'] = num_good_tst / num_bad_tst\n",
    "        FDR_oot.loc[i, '#g'] = num_good_oot - FDR_oot.loc[i-1, 'cg']\n",
    "        FDR_oot.loc[i, '#b'] = num_bad_oot - FDR_oot.loc[i-1, 'cb']\n",
    "        FDR_oot.loc[i,'#recs'] = FDR_oot.loc[i, '#g'] + FDR_oot.loc[i, '#b']\n",
    "        FDR_oot.loc[i, '%g'] = 100* (num_good_oot - FDR_oot.loc[i-1, 'cg']) / (num_tot_oot - FDR_oot.loc[i-1, 'tot'])\n",
    "        FDR_oot.loc[i, '%b'] = 100 - FDR_oot.loc[i, '%g']\n",
    "        FDR_oot.loc[i, '%cg'] = 100 * num_good_oot / good_tot_oot\n",
    "        FDR_oot.loc[i, 'FDR'] = 100 * num_bad_oot / bad_tot_oot\n",
    "        FDR_oot.loc[i, 'KS'] = FDR_oot.loc[i, 'FDR'] - FDR_oot.loc[i, '%cg']\n",
    "        FDR_oot.loc[i, 'FPR'] = num_good_oot / num_bad_oot\n",
    "\n",
    "FDR_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR3.to_csv('FDR3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR_trn.to_csv('FDR_trn.csv', index=False)\n",
    "FDR_tst.to_csv('FDR_tst.csv', index=False)\n",
    "FDR_oot.to_csv('FDR_oot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR_oot['Fraud_savings']=FDR_oot['cb']*2000\n",
    "FDR_oot['Lost_sales']=FDR_oot['cg']*50\n",
    "FDR_oot['Overall_savings']=FDR_oot['Fraud_savings']-FDR_oot['Lost_sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin</th>\n",
       "      <th>#recs</th>\n",
       "      <th>#g</th>\n",
       "      <th>#b</th>\n",
       "      <th>%g</th>\n",
       "      <th>%b</th>\n",
       "      <th>tot</th>\n",
       "      <th>cg</th>\n",
       "      <th>cb</th>\n",
       "      <th>%cg</th>\n",
       "      <th>FDR</th>\n",
       "      <th>KS</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Fraud_savings</th>\n",
       "      <th>Lost_sales</th>\n",
       "      <th>Overall_savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>42.148760</td>\n",
       "      <td>57.851240</td>\n",
       "      <td>121.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.427924</td>\n",
       "      <td>39.106145</td>\n",
       "      <td>38.678221</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>137450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>74.380165</td>\n",
       "      <td>25.619835</td>\n",
       "      <td>242.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.183084</td>\n",
       "      <td>56.424581</td>\n",
       "      <td>55.241497</td>\n",
       "      <td>1.396040</td>\n",
       "      <td>202000.0</td>\n",
       "      <td>7050.0</td>\n",
       "      <td>194950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>90.909091</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>363.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2.106058</td>\n",
       "      <td>62.569832</td>\n",
       "      <td>60.463774</td>\n",
       "      <td>2.241071</td>\n",
       "      <td>224000.0</td>\n",
       "      <td>12550.0</td>\n",
       "      <td>211450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>98.347107</td>\n",
       "      <td>1.652893</td>\n",
       "      <td>484.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>3.104548</td>\n",
       "      <td>63.687151</td>\n",
       "      <td>60.582603</td>\n",
       "      <td>3.245614</td>\n",
       "      <td>228000.0</td>\n",
       "      <td>18500.0</td>\n",
       "      <td>209500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11613.0</td>\n",
       "      <td>11434.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>95.938916</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4.061084</td>\n",
       "      <td>63.877095</td>\n",
       "      <td>358000.0</td>\n",
       "      <td>571700.0</td>\n",
       "      <td>-213700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11734.0</td>\n",
       "      <td>11555.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>96.954187</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3.045813</td>\n",
       "      <td>64.553073</td>\n",
       "      <td>358000.0</td>\n",
       "      <td>577750.0</td>\n",
       "      <td>-219750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11855.0</td>\n",
       "      <td>11676.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>97.969458</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.030542</td>\n",
       "      <td>65.229050</td>\n",
       "      <td>358000.0</td>\n",
       "      <td>583800.0</td>\n",
       "      <td>-225800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11976.0</td>\n",
       "      <td>11797.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>98.984729</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.015271</td>\n",
       "      <td>65.905028</td>\n",
       "      <td>358000.0</td>\n",
       "      <td>589850.0</td>\n",
       "      <td>-231850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12097.0</td>\n",
       "      <td>11918.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.581006</td>\n",
       "      <td>358000.0</td>\n",
       "      <td>595900.0</td>\n",
       "      <td>-237900.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bin  #recs     #g    #b          %g         %b      tot       cg  \\\n",
       "0      0.0    0.0    0.0   0.0    0.000000   0.000000      0.0      0.0   \n",
       "1      1.0  121.0   51.0  70.0   42.148760  57.851240    121.0     51.0   \n",
       "2      2.0  121.0   90.0  31.0   74.380165  25.619835    242.0    141.0   \n",
       "3      3.0  121.0  110.0  11.0   90.909091   9.090909    363.0    251.0   \n",
       "4      4.0  121.0  119.0   2.0   98.347107   1.652893    484.0    370.0   \n",
       "..     ...    ...    ...   ...         ...        ...      ...      ...   \n",
       "96    96.0  121.0  121.0   0.0  100.000000   0.000000  11613.0  11434.0   \n",
       "97    97.0  121.0  121.0   0.0  100.000000   0.000000  11734.0  11555.0   \n",
       "98    98.0  121.0  121.0   0.0  100.000000   0.000000  11855.0  11676.0   \n",
       "99    99.0  121.0  121.0   0.0  100.000000   0.000000  11976.0  11797.0   \n",
       "100  100.0  121.0  121.0   0.0  100.000000   0.000000  12097.0  11918.0   \n",
       "\n",
       "        cb         %cg         FDR         KS        FPR  Fraud_savings  \\\n",
       "0      0.0    0.000000    0.000000   0.000000   0.000000            0.0   \n",
       "1     70.0    0.427924   39.106145  38.678221   0.728571       140000.0   \n",
       "2    101.0    1.183084   56.424581  55.241497   1.396040       202000.0   \n",
       "3    112.0    2.106058   62.569832  60.463774   2.241071       224000.0   \n",
       "4    114.0    3.104548   63.687151  60.582603   3.245614       228000.0   \n",
       "..     ...         ...         ...        ...        ...            ...   \n",
       "96   179.0   95.938916  100.000000   4.061084  63.877095       358000.0   \n",
       "97   179.0   96.954187  100.000000   3.045813  64.553073       358000.0   \n",
       "98   179.0   97.969458  100.000000   2.030542  65.229050       358000.0   \n",
       "99   179.0   98.984729  100.000000   1.015271  65.905028       358000.0   \n",
       "100  179.0  100.000000  100.000000   0.000000  66.581006       358000.0   \n",
       "\n",
       "     Lost_sales  Overall_savings  \n",
       "0           0.0              0.0  \n",
       "1        2550.0         137450.0  \n",
       "2        7050.0         194950.0  \n",
       "3       12550.0         211450.0  \n",
       "4       18500.0         209500.0  \n",
       "..          ...              ...  \n",
       "96     571700.0        -213700.0  \n",
       "97     577750.0        -219750.0  \n",
       "98     583800.0        -225800.0  \n",
       "99     589850.0        -231850.0  \n",
       "100    595900.0        -237900.0  \n",
       "\n",
       "[101 rows x 16 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_oot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211450.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_oot['Overall_savings'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(x='bin',y='Fraud_savings',data=FDR_oot, label='Fraud savings')\n",
    "sns.lineplot(x='bin',y='Lost_sales',data=FDR_oot,label='Lost Sales')\n",
    "sns.lineplot(x='bin',y='Overall_savings',data=FDR_oot, label= 'Overall Savings')\n",
    "plt.axvline(x = 3, color = 'b', label = 'axvline - full height')\n",
    "# plt.yaxis.set_major_formatter('${y:1.0f}')\n",
    "plt.xlim([0, 40])\n",
    "plt.ylim([0,400000])\n",
    "plt.ylabel('Money in dollars')\n",
    "plt.xlabel('OOT population % bins')\n",
    "plt.xticks(np.arange(0,50,3))\n",
    "# plt.figure(figsize=(400000,20111))\n",
    "plt.legend(['Fraud savings','Lost Sales','Overall Savings'], loc='upper center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration:  0:04:47.132435\n"
     ]
    }
   ],
   "source": [
    "print(\"duration: \", datetime.now() - start_time)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
